### elasticsearch(es)写入速度提升

0. es写入数据时分3部分:
   
   a. write: 文档数据到Luence的**"memory buffer"缓冲区**, 并存到 translog buffer;
   
   b. refresh: 内存缓存中的文档数据, 刷新到FileSystemCache缓存层中, 生成倒排索引文件segment, 此时索引即可查询到该文件
   , 同时memory buffer缓冲区的被清空;
   
   c. flush: 每隔5s, refresh结束后, 将translog buffer的数据flush到磁盘中;
   
   d. 增量flush: 定期定量的从FileSystemCache, 结合translog的文件内容, flush到磁盘中(不是很懂)。
1. bulk 批量写入;
```python
from elasticsearch import Elasticsearch
from elasticsearch import helpers
es = Elasticsearch(["localhost"], http_auth=("username", "password"), port=9200, use_ssl=False)
results = []
action = [{
            "_index": "index",
            "_type": "_doc",
            "_id": data.get("id"),
            "_source": data
        } for data in results]
helpers.bulk(es, action)
```
2. 多线程写入;(1,2均需要注意批量写入和并发写入的瓶颈, 需要压测, 否则会失败);
   
3. 更改refresh_interval间隔, 数据写入后需要索引刷新才能查询到, refresh_interval默认刷新时间是1s, -1即为禁用;
   问题: 禁用refresh后是直接进行flush操作吗?会存在数据丢失吗?
```
PUT index/_settings
{
"index.refresh_interval": "-1"
}
```
4. 禁用副分片;
```
PUT /index/_settings
{
  "index" : {
    "number_of_replicas" : 0
  }
}
```
5. 文档id由es自动设置生成, 自己设置id后, 每次导入数据时会检测id是否存在, 减少此部分时间;
   
6. 建立索引时, 设计合理的mapping, 对于不需要查询的字段不进行索引, 从而减少倒排索引的大小;
```json
{
  "mappings": {
    "properties": {
   "user": {
      "type": "object",
      "enabled": false
   }
}}}
```
7. 其余没用到, 等待补充。

